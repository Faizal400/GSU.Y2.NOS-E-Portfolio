# Week 7 - Introduction to Networks & Operating Systems

> These notes provide an introduction to operating systems, their basic elements, evolution, and key concepts (week 7 stuff).

## Operating Systems (OS)
- Exploits hardware resources of one or more processors.
- Provides a set of services to system users.
- Manages secondary memory and I/O devices.

## Basic Elements of a Computer System
The fundamental components of a computer system include:
- **Processor (CPU)**: Controls the operation of the computer and performs data processing functions. Referred to as the Central Processing Unit.
- **Main Memory**: Stores data and programs. Typically volatile (contents lost when power is off). Referred to as real or primary memory.
- **I/O Modules**: Move data between the computer and its external environment (e.g., disks, communication equipment).
- **System Bus**: Provides communication between the processor, main memory, and I/O modules. Essentially a set of wires that allows data to travel.

### Computer Components: Top-Level View
The relationships between the components are often visualized as follows:

`PC -> MAR -> MBR
I/O AR -> I/O BR`
- **PC**: Program Counter - Holds the address of the next instruction to be fetched.
- **IR**: Instruction Register - Holds the instruction that was fetched.
- **MAR**: Memory Address Register - Holds the address of a memory location.
- **MBR**: Memory Buffer Register - Holds data being written to or read from memory.
- **I/O AR**: Input/Output Address Register - Specifies a particular I/O device.
- **I/O BR**: Input/Output Buffer Register - Used for data exchange between an I/O module and the processor.

### Instruction Execution
- **Fetch Stage**: Processor reads (fetches) instructions from memory. The program counter (PC) holds the address of the next instruction, and it's incremented after each fetch. The fetched instruction is loaded into the Instruction Register (IR).
- **Execute Stage**: Processor interprets the instruction and performs the required action. These actions may include:
  - Processor-memory: Data transfer between CPU and memory.
  - Processor-I/O: Data transfer between CPU and I/O module.
  - Data processing: Arithmetic or logical operations on data.
  - Control: Altering the sequence of execution (e.g., jumps).

### Interrupts
- Mechanism by which other modules (I/O, timer, etc.) may interrupt the normal sequencing of the processor.
- Provided to improve processor utilization. I/O devices are often slower than the processor, so interrupts allow the processor to continue working on other tasks while waiting for I/O operations to complete.

### Classes of Interrupts
- **Program**: Generated by a condition that occurs as a result of an instruction execution (e.g., arithmetic overflow, division by zero, illegal instruction, memory access violation).
- **Timer**: Generated by a timer within the processor, allowing the OS to perform functions regularly.
- **I/O**: Generated by an I/O controller, signaling completion of an operation or an error condition.
- **Hardware**: Generated by a failure, such as power failure or memory parity error.

## Memory Hierarchy
The memory hierarchy is based on design constraints related to:
- **How much?**: Capacity requirements.
- **How fast?**: Speed of memory access.
- **How expensive?**: Cost of memory components.

### Memory Relationships
- Greater capacity = Lower cost per bit = Slower access time.
- Smaller capacity = Higher cost per bit = Faster access time.
The hierarchy is structured as follows (from fastest/most expensive to slowest/least expensive):
- Registers (CPU)
- Cache Memory
- Main Memory (RAM)
- Secondary Memory (Disk)
- Off-line Storage (Tape, Optical Disks)

### Principle of Locality
- Memory references by the processor tend to cluster.
- Data is organized such that the percentage of accesses to each successively lower level is substantially less than that of the level above.

### Cache Memory
- Small, fast memory placed between the processor and main memory.
- Invisible to the OS.
- Exploits the principle of locality.
- The CPU first checks if the required data is in the cache. If so, it retrieves it quickly (cache hit). If not (cache miss), the data is fetched from main memory and copied into the cache.

### Cache Design Considerations
- **Cache Size**: The amount of memory to dedicate to the cache.
- **Block Size**: The unit of data exchanged between cache and main memory. Small caches have significant impact on performance.
- **Number of Cache Levels**: Single, Two-Level (L1, L2) or Three-Level (L1, L2, L3) caches.
- **Mapping Function**: Determines which cache location a block will occupy. More flexible mapping is more complex.
- **Write Algorithm**: How and when data is written to main memory from the cache.
- **Replacement Algorithm**: Which block to replace when a new block needs to be loaded into a full cache.

## I/O Techniques
Three techniques are possible for I/O operations:
- **Programmed I/O**: The processor issues an I/O command and waits for the I/O module to complete the operation. The processor periodically checks the status of the I/O module. This severely degrades system performance.
- **Interrupt-Driven I/O**: The processor issues an I/O command and then continues with other work. The I/O module interrupts the processor when it is ready to exchange data. More efficient than programmed I/O but still requires active intervention of the processor.
- **Direct Memory Access (DMA)**: A separate DMA module transfers data directly to and from memory without going through the processor. The processor is involved only at the beginning and end of the transfer. This is the most efficient method.
- When the processor wishes to read or write data it issues a command to the DMA module containing:
  - Whether a read or write is requested
  - The address of the I/O device involved
  - The starting location in memory to read/write
  - The number of words to be read/written

## Symmetric Multiprocessors (SMP)
- A stand-alone computer system with:
  - Two or more similar processors of comparable capability.
  - Processors sharing the same main memory and interconnected by a bus or internal connection scheme.
  - Processors sharing access to I/O devices.
  - All processors capable of performing the same functions.
  - An integrated operating system providing interaction between processors and their programs.

### SMP Advantages
- **Performance**: Greater performance if work can be done in parallel.
- **Availability**: Failure of a single processor does not halt the machine.
- **Incremental Growth**: An additional processor can be added to enhance performance.
- **Scaling**: Vendors can offer a range of products with different price and performance characteristics.

## Multicore Computer
- Combines two or more processors (cores) on a single piece of silicon (die).
- Each core consists of all of the components of an independent processor.
- Multicore chips also include L2 cache and, in some cases, L3 cache.

## Operating Systems (Revisited)
- A program that controls the execution of application programs.
- An interface between applications and hardware.

### Main Objectives of an OS
- **Convenience**: Making the computer easier to use.
- **Efficiency**: Using computer resources effectively.
- **Ability to evolve**: Accommodating new hardware and software.

### Operating System Services
- Program development: Providing tools for writing programs.
- Program execution: Loading and running programs.
- Access I/O devices: Providing a uniform interface to I/O devices.
- Controlled access to files: Managing file systems.
- System access: Controlling access to the system.
- Error detection and response: Handling errors.
- Accounting: Tracking resource usage.

## Evolution of Operating Systems
A major OS will evolve over time due to:
- Hardware upgrades.
- New types of hardware.
- New services.
- Fixes.

### Stages of Evolution
- Serial Processing
- Simple Batch Systems
- Multiprogrammed Systems
- Time Sharing Systems

## Major Achievements in OS Development
- **Processes**: Fundamental to the structure of operating systems.
- **Memory management**: Efficiently managing memory resources.
- **Information protection and security**: Protecting data and system resources.
- **Scheduling and resource management**: Allocating resources to processes.
- **System structure**: How the OS is organized.

## Process
- A program in execution.
- An instance of a running program.
- The entity that can be assigned to and executed on a processor.
- A unit of activity characterized by a single sequential thread of execution, a current state, and an associated set of system resources.

### Causes of Errors in Concurrent Processing
- **Nondeterminate program operation**: Programs may interfere with each other due to shared memory.
- **Deadlocks**: Two or more programs are hung up waiting for each other.
- **Improper synchronization**: Loss or duplication of signals due to design flaws.
- **Failed mutual exclusion**: Multiple programs attempting to use a shared resource simultaneously.

### Components of a Process
- An executable program (code).
- The associated data needed by the program (variables, workspace, buffers).
- The execution context (or “process state”) of the program.

## Memory Management
The OS has five principal storage management responsibilities:
- Process isolation: Preventing processes from interfering with each other's memory.
- Automatic allocation and management: Automatically allocating and managing memory resources.
- Support of modular programming: Supporting modular program design.
- Protection and access control: Controlling access to memory resources.
- Long-term storage: Managing long-term storage of data.

### Virtual Memory
- A facility that allows programs to address memory from a logical point of view, without regard to the amount of main memory physically available.
- Designed to allow multiple user jobs to reside in main memory concurrently.

### Paging
- Allows processes to be comprised of a number of fixed-size blocks, called pages.
- A program references a word by means of a virtual address, consisting of a page number and an offset within the page.
- Each page of a process may be located anywhere in main memory.
- Provides a dynamic mapping between the virtual address and a real (physical) address.

## Information Protection and Security
Main issues:
- **Availability**: Ensuring resources are accessible when needed.
- **Confidentiality**: Protecting information from unauthorized access.
- **Data integrity**: Ensuring data is accurate and consistent.
- **Authenticity**: Verifying the identity of users and systems.

## Scheduling and Resource Management
- Key responsibility of an OS is managing resources.
- Resource allocation policies must consider fairness, efficiency, and response time.

## Different Architectural Approaches for OS Design
- Microkernel architecture
- Multithreading
- Symmetric multiprocessing
- Distributed operating systems
- Object-oriented design

### Microkernel Architecture
- Assigns only a few essential functions to the kernel:
  - Address space management
  - Interprocess communication (IPC)
  - Basic scheduling
- Simplifies implementation, provides flexibility, and is well-suited to a distributed environment.

### Multithreading
- A technique in which a process, executing an application, is divided into threads that can run concurrently.
  - **Thread**: Dispatchable unit of work, including a processor context and its own data area for a stack. Executes sequentially and is interruptible.
  - **Process**: A collection of one or more threads and associated system resources.
- By breaking a single application into multiple threads, a programmer has greater control over the modularity of the application and the timing of application-related events.

### Symmetric Multiprocessing (SMP)
- Refers to a computer hardware architecture and also to the OS behavior that exploits that architecture.
- The OS of an SMP schedules processes or threads across all of the processors.
- The OS must provide tools and functions to exploit the parallelism in an SMP system.
- Multithreading and SMP are often discussed together, but the two are independent facilities.

### SMP Advantages
- **Performance**: More than one process can be running simultaneously, each on a different processor.
- **Availability**: Failure of a single process does not halt the system.
- **Incremental Growth**: Performance of a system can be enhanced by adding an additional processor.
- **Scaling**: Vendors can offer a range of products based on the number of processors configured in the system.

### Distributed Operating System
- Provides the illusion of a single main memory space and a single secondary memory space plus other unified access facilities, such as a distributed file system.
- State of the art for distributed operating systems lags that of uniprocessor and SMP operating systems.

### Object-Oriented Design
- Lends discipline to the process of adding modular extensions to a small kernel.
- Enables programmers to customize an operating system without disrupting system integrity.
- Also eases the development of distributed tools and full-blown distributed operating systems.

## Fault Tolerance
- Refers to the ability of a system or component to continue normal operation despite the presence of hardware or software faults.
- Typically involves some degree of redundancy.
- Intended to increase the reliability of a system.
- Typically comes with a cost in financial terms or performance.
- The extent adoption of fault tolerance measures must be determined by how critical the resource is.

### Fundamental Concepts
- **Reliability** `(R(t))`: The probability of its correct operation up to time t, given that the system was operating correctly at time t=0.
- **Mean Time To Failure (MTTF)**: The average time a device or system will work before failing.
- **Mean Time To Repair (MTTR)**: The average time it takes to repair or replace a faulty element.
- **Availability**: The fraction of time the system is available to service users’ requests. Availability is related to MTTF and MTTR by the following equation:
![image](https://github.com/user-attachments/assets/4ad95eb0-d292-4df5-bf85-817ecbc8d511)
> This equation expresses availability as the proportion of time the system is functioning correctly relative to the total time (functioning plus repair time).

### Availability Classes
![image](https://github.com/user-attachments/assets/76a23197-3264-4354-ac62-daf51de1f34d)

### Faults
- Are defined by the IEEE Standards Dictionary as an erroneous hardware or software state resulting from:
  - Component failure
  - Operator error
  - Physical interference from the environment
  - Design error
  - Program error
  - Data structure error
- The standard also states that a fault manifests itself as:
  - A defect in a hardware device or component
  - An incorrect step, process, or data definition in a computer program

### Fault Categories
- **Permanent**: A fault that, after it occurs, is always present. The fault persists until the faulty component is replaced or repaired.
- **Temporary**: A fault that is not present all the time for all operating conditions.
  - **Transient**: A fault that occurs only once.
  - **Intermittent**: A fault that occurs at multiple, unpredictable times.

### Methods of Redundancy
- **Spatial (physical) redundancy**: Involves the use of multiple components that either perform the same function simultaneously or are configured so that one component is available as a backup in case of the failure of another component.
- **Temporal redundancy**: Involves repeating a function or operation when an error is detected. Is effective with temporary faults but not useful for permanent faults.
- **Information redundancy**: Provides fault tolerance by replicating or coding data in such a way that bit errors can be both detected and corrected.
